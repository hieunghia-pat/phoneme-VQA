EXECUTOR: "PhonemeSaL_Executor"

## Tokenizer

vocab_path: "checkpoints/phoneme-sal"
annotation_paths:
  - datasets/ViTextVQA-dataset/ViTextVQA_train.json
  - datasets/ViTextVQA-dataset/ViTextVQA_dev.json
  - datasets/ViTextVQA-dataset/ViTextVQA_test.json

## Training param
DEVICE: cpu

SAVE: TRUE
SAVE_PATH: "checkpoints/phoneme-sal"

LR: 0.00005
BETAS: 
  - 0.9
  - 0.98

warmup_step: 1000

NUM_EPOCHS: 20
NUM_FREEZE_EPOCH: 0

TRAIN_BATCH_SIZE: 16
EVAL_BATCH_SIZE: 32
PREDICT_BATCH_SIZE: 32

max_predict_length: 128
max_eval_length: 80

get_predict_score: TRUE

##DATA
max_ocr_element: 32
max_ocr_length: 128
max_obj_element: 32
max_obj_length: 128
max_q_length: 80
max_a_length: 40

base_ocr_feature_path: "datasets/ViTextVQA-dataset/features/swintext_spotter"
base_obj_feature_path: "datasets/ViTextVQA-dataset/features/vinvl_vinvl"

qa_train_path: "datasets/ViTextVQA-dataset/train.csv"
qa_val_path: "datasets/ViTextVQA-dataset/dev.csv"
qa_predict_path: "datasets/ViTextVQA-dataset/test.csv"

context_token: "<c>"

NUMWORKERS: 0

## MODEL
MODEL_CLASS: "PhonemeSaL"

MODEL_MOD_CONFIG_CLASS: "CustomizedSaL_config" # model modified config class

backbone_name: "VietAI/vit5-base"

ocr_hidden: 512

obj_hidden: 2048

max_2d_position_embeddings: 1024

num_decoder_layers: 4

encoder_name: "VietAI/vit5-base"

n_head: 12

## Inference

isgreedy: True
num_beam: 1

