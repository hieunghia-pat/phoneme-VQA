EXECUTOR: "LaTr_Executor"
DecodeTokenizer: "BPE_Tokenizer"

## Tokenizer

bpe_step: 1000
vocab_save_path: "PhonoVQA/models/vocab.json"
max_vocab_size: 3000

## Training param
DEVICE: "cuda"

SAVE: TRUE
SAVE_PATH: "PhonoVQA/models/"

LR: 0.00005
BETAS: 
  - 0.9
  - 0.98

warmup_step: 2000

NUM_EPOCHS: 10
TRAIN_BATCH_SIZE: 16
EVAL_BATCH_SIZE: 32
PREDICT_BATCH_SIZE: 32

max_predict_length: 128
max_eval_length: 20

get_predict_score: TRUE

##DATA
ocr_path: "./ocr"
max_ocr_element: 50
max_ocr_length: 100
max_q_length: 30
max_a_length: 128

base_img_path: "./latr_img"

qa_train_path: ""
qa_val_path: ""
qa_predict_path: ""

NUMWORKERS: 2

## MODEL
MODEL_CLASS: "LaTr"

MODEL_MOD_CONFIG_CLASS: "LaTr_config" # model modified config class

backbone_name: "VietAI/vit5-base"

vit_model_name: "google/vit-base-patch16-224-in21k"

max_2d_position_embeddings: 1024

## Inference

isgreedy: False
num_beam: 2

